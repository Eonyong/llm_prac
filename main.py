"""
SimpleLLM - ë©”ì¸ ì‹¤í–‰ íŒŒì¼

í•œêµ­ì–´/ì˜ì–´ ì§ˆë¬¸-ë‹µë³€ ì§€ì›
ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€ ìƒì„± ë° DB ì €ì¥
ë‹µë³€ í‰ê°€ ì‹œìŠ¤í…œ í¬í•¨
"""

import torch
import torch.nn as nn
import tiktoken
import os
import sys
import re
import json
from datetime import datetime

from layer_normalization import SimpleLLM


class LLMChatbot:
    """í•œêµ­ì–´/ì˜ì–´ ì§€ì› QA ì±—ë´‡ with LLM ë°±ì—”ë“œ"""

    def __init__(self, checkpoint_path='checkpoints/best_model.pt', qa_database_path='qa_database.json'):
        """
        Args:
            checkpoint_path: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ
            qa_database_path: ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
        """
        print("="*70)
        print("ğŸ¤– SimpleLLM ì±—ë´‡ ì´ˆê¸°í™” ì¤‘...")
        print("="*70)
        print()

        # QA ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
        self.qa_database_path = qa_database_path
        self.qa_database = self.load_qa_database()
        print(f"ğŸ“‚ QA ë°ì´í„°ë² ì´ìŠ¤: {len(self.qa_database)} ê°œ ì €ì¥ë¨")

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            print("âœ… GPU ì‚¬ìš© (CUDA)")
        elif torch.backends.mps.is_available():
            self.device = torch.device('mps')
            print("âœ… GPU ì‚¬ìš© (Apple Silicon)")
        else:
            self.device = torch.device('cpu')
            print("âš ï¸  CPU ì‚¬ìš©")

        # í† í¬ë‚˜ì´ì €
        self.tokenizer = tiktoken.get_encoding("gpt2")
        self.vocab_size = self.tokenizer.n_vocab

        # ì²´í¬í¬ì¸íŠ¸ í™•ì¸ (ì„ íƒì‚¬í•­)
        self.model = None
        self.trained = False

        if os.path.exists(checkpoint_path):
            try:
                # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
                print(f"\nğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ: {checkpoint_path}")
                checkpoint = torch.load(checkpoint_path, map_location=self.device)

                # ëª¨ë¸ ì„¤ì • ì¶”ì¶œ
                config = checkpoint.get('config', {})

                # ëª¨ë¸ ìƒì„±
                self.model = SimpleLLM(
                    vocab_size=self.vocab_size,
                    d_embed=config.get('d_embed', 256),
                    num_heads=config.get('num_heads', 4),
                    num_layers=config.get('num_layers', 4),
                    max_seq_len=config.get('max_seq_len', 256),
                    dropout=0.0  # ì¶”ë¡  ì‹œì—ëŠ” dropout ë¹„í™œì„±í™”
                ).to(self.device)

                # ê°€ì¤‘ì¹˜ ë¡œë“œ
                self.model.load_state_dict(checkpoint['model_state_dict'])
                self.model.eval()

                # í•™ìŠµ ì •ë³´
                epoch = checkpoint.get('epoch', 0)
                val_loss = checkpoint.get('best_val_loss', 0)

                print(f"âœ… LLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                print(f"   - í•™ìŠµ ì—í¬í¬: {epoch + 1}")
                print(f"   - ìµœê³  ê²€ì¦ ì†ì‹¤: {val_loss:.4f}")

                self.trained = True
            except Exception as e:
                print(f"âš ï¸  LLM ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("   ì›¹ ê²€ìƒ‰ ê¸°ë°˜ìœ¼ë¡œë§Œ ë™ì‘í•©ë‹ˆë‹¤.")
        else:
            print(f"âš ï¸  ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ. ì›¹ ê²€ìƒ‰ ê¸°ë°˜ìœ¼ë¡œë§Œ ë™ì‘í•©ë‹ˆë‹¤.")

        print()

        # ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥
        self.web_search_enabled = True
        self.search_cache = {}

    def load_qa_database(self):
        """ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        if os.path.exists(self.qa_database_path):
            try:
                with open(self.qa_database_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  DB ë¡œë“œ ì‹¤íŒ¨: {e}")
                return {}
        return {}

    def save_qa_database(self):
        """ì§ˆë¬¸-ë‹µë³€ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        try:
            with open(self.qa_database_path, 'w', encoding='utf-8') as f:
                json.dump(self.qa_database, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸  DB ì €ì¥ ì‹¤íŒ¨: {e}")

    def normalize_question(self, question):
        """ì§ˆë¬¸ ì •ê·œí™” (ê²€ìƒ‰ìš©)"""
        normalized = question.lower().strip()
        normalized = re.sub(r'[?!.,;:]', '', normalized)
        normalized = re.sub(r'\s+', ' ', normalized)
        return normalized

    def search_qa_database(self, question):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬í•œ ì§ˆë¬¸ ê²€ìƒ‰"""
        normalized_q = self.normalize_question(question)

        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì§ˆë¬¸ ì°¾ê¸°
        for stored_q, data in self.qa_database.items():
            if self.normalize_question(stored_q) == normalized_q:
                # ì ‘ê·¼ íšŸìˆ˜ ì¦ê°€
                data['access_count'] = data.get('access_count', 0) + 1
                data['last_accessed'] = datetime.now().isoformat()
                self.save_qa_database()
                print(f"  ğŸ“š DBì—ì„œ ì°¾ìŒ! (ì ‘ê·¼: {data['access_count']}íšŒ)")
                return data

        # ìœ ì‚¬í•œ ì§ˆë¬¸ ì°¾ê¸° (í‚¤ì›Œë“œ ë§¤ì¹­)
        question_keywords = set(normalized_q.split())
        best_match = None
        max_similarity = 0

        for stored_q, data in self.qa_database.items():
            stored_normalized = self.normalize_question(stored_q)
            stored_keywords = set(stored_normalized.split())

            # ê³µí†µ í‚¤ì›Œë“œ ê°œìˆ˜ ê³„ì‚°
            common_keywords = question_keywords & stored_keywords
            similarity = len(common_keywords) / max(len(question_keywords), 1)

            if similarity > max_similarity and similarity > 0.5:  # 50% ì´ìƒ ìœ ì‚¬
                max_similarity = similarity
                best_match = data

        if best_match:
            best_match['access_count'] = best_match.get('access_count', 0) + 1
            best_match['last_accessed'] = datetime.now().isoformat()
            self.save_qa_database()
            print(f"  ğŸ“š ìœ ì‚¬ ì§ˆë¬¸ ë°œê²¬! (ìœ ì‚¬ë„: {max_similarity:.0%}, ì ‘ê·¼: {best_match['access_count']}íšŒ)")
            return best_match

        return None

    def add_qa_pair(self, question, answer, rating=None):
        """ì§ˆë¬¸-ë‹µë³€ ìŒì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€"""
        if question in self.qa_database:
            # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
            self.qa_database[question]['answer'] = answer
            self.qa_database[question]['access_count'] = self.qa_database[question].get('access_count', 0) + 1
            self.qa_database[question]['last_accessed'] = datetime.now().isoformat()
            if rating is not None:
                ratings = self.qa_database[question].get('ratings', [])
                ratings.append(rating)
                self.qa_database[question]['ratings'] = ratings
                self.qa_database[question]['avg_rating'] = sum(ratings) / len(ratings)
        else:
            # ìƒˆ ë°ì´í„° ì¶”ê°€
            self.qa_database[question] = {
                'answer': answer,
                'timestamp': datetime.now().isoformat(),
                'access_count': 1,
                'last_accessed': datetime.now().isoformat(),
                'ratings': [rating] if rating is not None else [],
                'avg_rating': rating if rating is not None else None
            }
        self.save_qa_database()

    def is_question(self, text):
        """ì…ë ¥ì´ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
        question_patterns = [
            r'\?$',
            r'^(what|where|when|who|why|how|which|is|are|do|does|can|could|would|should)',
            r'(ë¬´ì—‡|ì–´ë””|ì–¸ì œ|ëˆ„êµ¬|ì™œ|ì–´ë–»ê²Œ|ë¬´ìŠ¨|ì–´ëŠ)',
            r'(ì¸ê°€ìš”|ì¸ì§€|ì…ë‹ˆê¹Œ|ì¸ê°€|í• ê¹Œ|ê¹Œìš”)$'
        ]

        text_lower = text.lower().strip()
        for pattern in question_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        return False

    def is_response_valid(self, original_prompt, response):
        """ìƒì„±ëœ ì‘ë‹µì´ ìœ íš¨í•œì§€ íŒë‹¨"""
        if not response or response == original_prompt:
            return False

        response_only = response[len(original_prompt):].strip()
        if len(response_only) < 10:
            return False

        words = response_only.split()
        if len(words) > 5:
            unique_ratio = len(set(words)) / len(words)
            if unique_ratio < 0.3:
                return False

        return True

    def search_web(self, query):
        """í•œêµ­ì–´/ì˜ì–´ ì›¹ ê²€ìƒ‰"""
        if query in self.search_cache:
            print("  ğŸ“¦ ìºì‹œì—ì„œ ê°€ì ¸ì˜´")
            return self.search_cache[query]

        print(f"  ğŸ” ì›¹ ê²€ìƒ‰ ì¤‘...")

        # í•œêµ­ì–´ ì§€ì‹ ë² ì´ìŠ¤
        korean_knowledge = {
            "ì¸ê³µì§€ëŠ¥": "ì¸ê³µì§€ëŠ¥(AI)ì€ ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥, ì¶”ë¡ ëŠ¥ë ¥, ì§€ê°ëŠ¥ë ¥ì„ ì¸ê³µì ìœ¼ë¡œ êµ¬í˜„í•œ ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ê¸°ê³„í•™ìŠµ, ë”¥ëŸ¬ë‹ ë“±ì˜ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ì¸ì‹, ìŒì„± ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì— í™œìš©ë©ë‹ˆë‹¤.",
            "ë¨¸ì‹ ëŸ¬ë‹": "ë¨¸ì‹ ëŸ¬ë‹ì€ ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ, ì»´í“¨í„°ê°€ ëª…ì‹œì ìœ¼ë¡œ í”„ë¡œê·¸ë˜ë°ë˜ì§€ ì•Šì•„ë„ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì§€ë„í•™ìŠµ, ë¹„ì§€ë„í•™ìŠµ, ê°•í™”í•™ìŠµ ë“±ì˜ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤.",
            "ë”¥ëŸ¬ë‹": "ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ìˆ ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ì¸µì˜ ì‹ ê²½ë§ì„ ì‚¬ìš©í•˜ì—¬ ë³µì¡í•œ íŒ¨í„´ì„ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë©°, ì´ë¯¸ì§€ ì¸ì‹, ìŒì„± ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ ë“±ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.",
            "íŒŒì´ì¬": "íŒŒì´ì¬ì€ ì½ê¸° ì‰½ê³  ë°°ìš°ê¸° ì‰¬ìš´ ê³ ê¸‰ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. ì›¹ ê°œë°œ, ë°ì´í„° ë¶„ì„, ì¸ê³µì§€ëŠ¥, ìë™í™” ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì»¤ë®¤ë‹ˆí‹° ì§€ì›ì´ ì¥ì ì…ë‹ˆë‹¤.",
            "íŠ¸ëœìŠ¤í¬ë¨¸": "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” 2017ë…„ì— ì†Œê°œëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ë©°, GPT, BERT ë“± í˜„ëŒ€ ì–¸ì–´ ëª¨ë¸ì˜ ê¸°ì´ˆê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ìì—°ì–´ì²˜ë¦¬": "ìì—°ì–´ì²˜ë¦¬(NLP)ëŠ” ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ë¶„ì•¼ì…ë‹ˆë‹¤. ë²ˆì—­, ìš”ì•½, ê°ì • ë¶„ì„, ì§ˆë¬¸ ë‹µë³€ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
            "ì±—ë´‡": "ì±—ë´‡ì€ ì‚¬ìš©ìì™€ ëŒ€í™”ë¥¼ ë‚˜ëˆ„ëŠ” ì¸ê³µì§€ëŠ¥ í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤. ê·œì¹™ ê¸°ë°˜, ê²€ìƒ‰ ê¸°ë°˜, ìƒì„± ê¸°ë°˜ ë“± ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„ë˜ë©°, ê³ ê° ì„œë¹„ìŠ¤, ì •ë³´ ì œê³µ, ì—”í„°í…Œì¸ë¨¼íŠ¸ ë“±ì— í™œìš©ë©ë‹ˆë‹¤.",
            "pytorch": "PyTorchëŠ” Facebook(Meta)ì´ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ë™ì  ê³„ì‚° ê·¸ë˜í”„ë¥¼ ì§€ì›í•˜ì—¬ ìœ ì—°í•œ ëª¨ë¸ ê°œë°œì´ ê°€ëŠ¥í•˜ë©°, ì—°êµ¬ì™€ ì‹¤ë¬´ì—ì„œ ë„ë¦¬ ì‚¬ìš©ë©ë‹ˆë‹¤.",
            "tensorflow": "TensorFlowëŠ” Googleì´ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ë¨¸ì‹ ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ í”Œë«í¼ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë©°, ì—°êµ¬ë¶€í„° í”„ë¡œë•ì…˜ê¹Œì§€ í­ë„“ê²Œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
            "llm": "ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì€ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ í•™ìŠµëœ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì…ë‹ˆë‹¤. GPT, Claude ë“±ì´ ëŒ€í‘œì ì´ë©°, í…ìŠ¤íŠ¸ ìƒì„±, ë²ˆì—­, ìš”ì•½ ë“± ë‹¤ì–‘í•œ ì–¸ì–´ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ë°ì´í„°": "ë°ì´í„°ëŠ” ì»´í“¨í„°ê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ì €ì¥ëœ ì •ë³´ì…ë‹ˆë‹¤. êµ¬ì¡°í™”ëœ ë°ì´í„°(DB), ë°˜êµ¬ì¡°í™”ëœ ë°ì´í„°(JSON), ë¹„êµ¬ì¡°í™”ëœ ë°ì´í„°(í…ìŠ¤íŠ¸, ì´ë¯¸ì§€) ë“±ì´ ìˆìŠµë‹ˆë‹¤.",
            "ë‚ ì”¨": f"ë‚ ì”¨ ì •ë³´ëŠ” ê¸°ìƒì²­ì´ë‚˜ ë‚ ì”¨ APIë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ì‹œê°„: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}",
            "ì‹œê°„": f"í˜„ì¬ ì‹œê°„ì€ {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}ì…ë‹ˆë‹¤.",
        }

        # ì˜ì–´ ì§€ì‹ ë² ì´ìŠ¤
        english_knowledge = {
            "artificial intelligence": "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, and self-correction.",
            "machine learning": "Machine Learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.",
            "deep learning": "Deep Learning is a subset of machine learning based on artificial neural networks with multiple layers. It's particularly effective for tasks like image and speech recognition.",
            "python": "Python is a high-level, interpreted programming language known for its simplicity and readability. It's widely used in web development, data science, AI, and automation.",
            "transformer": "Transformer is a deep learning model architecture introduced in 2017. It uses self-attention mechanisms and has become the foundation for modern language models like GPT and BERT.",
            "pytorch": "PyTorch is an open-source machine learning library developed by Facebook (Meta). It provides dynamic computation graphs and is widely used in research and production.",
            "llm": "Large Language Models (LLMs) are AI models trained on vast amounts of text data. Examples include GPT, Claude, and BERT, capable of various language tasks.",
        }

        # í†µí•© ì§€ì‹ ë² ì´ìŠ¤
        all_knowledge = {**korean_knowledge, **english_knowledge}

        # ì¿¼ë¦¬ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜
        query_lower = query.lower()

        # ì§ì ‘ ë§¤ì¹­
        for key, value in all_knowledge.items():
            if key in query_lower or query_lower in key:
                self.search_cache[query] = value
                return value

        # í‚¤ì›Œë“œ ë§¤ì¹­
        query_keywords = query_lower.split()
        best_match = None
        max_score = 0

        for key, value in all_knowledge.items():
            score = sum(1 for keyword in query_keywords if keyword in key or key in keyword)
            if score > max_score:
                max_score = score
                best_match = value

        if max_score > 0:
            self.search_cache[query] = best_match
            return best_match

        # ê¸°ë³¸ ë‹µë³€
        result = f"'{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."
        return result

    def generate_response(self, prompt, max_tokens=50, temperature=1.0, top_k=50):
        """
        í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±

        Args:
            prompt: ì…ë ¥ í…ìŠ¤íŠ¸
            max_tokens: ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
            temperature: ìƒ˜í”Œë§ ì˜¨ë„ (ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘í•¨)
            top_k: Top-k ìƒ˜í”Œë§

        Returns:
            generated_text: ìƒì„±ëœ ì „ì²´ í…ìŠ¤íŠ¸
        """
        if not self.trained:
            return "âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµì„ ì§„í–‰í•˜ì„¸ìš”."

        # í† í°í™”
        token_ids = self.tokenizer.encode(prompt)

        if len(token_ids) == 0:
            return "âŒ ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."

        token_tensor = torch.tensor(token_ids, device=self.device).unsqueeze(0)

        generated_tokens = token_ids.copy()

        with torch.no_grad():
            for i in range(max_tokens):
                # ì‹œí€€ìŠ¤ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                if token_tensor.size(1) > self.model.pos_embedding.num_embeddings:
                    token_tensor = token_tensor[:, -self.model.pos_embedding.num_embeddings:]

                # ìˆœì „íŒŒ
                logits = self.model(token_tensor)

                # ë§ˆì§€ë§‰ í† í°ì˜ ë¡œì§“
                next_token_logits = logits[0, -1, :] / temperature

                # Top-k ìƒ˜í”Œë§
                if top_k > 0:
                    # Top-k ê°’ë§Œ ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” -inf
                    top_k_values, top_k_indices = torch.topk(next_token_logits, min(top_k, next_token_logits.size(-1)))
                    next_token_logits = torch.full_like(next_token_logits, float('-inf'))
                    next_token_logits.scatter_(0, top_k_indices, top_k_values)

                # í™•ë¥  ê³„ì‚° ë° ìƒ˜í”Œë§
                probs = torch.softmax(next_token_logits, dim=-1)
                next_token = torch.multinomial(probs, num_samples=1).item()

                # ìƒì„±ëœ í† í° ì¶”ê°€
                generated_tokens.append(next_token)
                token_tensor = torch.cat([
                    token_tensor,
                    torch.tensor([[next_token]], device=self.device)
                ], dim=1)

                # ì¤„ë°”ê¿ˆì´ë‚˜ ë§ˆì¹¨í‘œê°€ ì—¬ëŸ¬ ê°œ ë‚˜ì˜¤ë©´ ì¢…ë£Œ
                if i > 10:  # ìµœì†Œ 10í† í°ì€ ìƒì„±
                    recent_text = self.tokenizer.decode(generated_tokens[-5:])
                    if recent_text.count('.') >= 2 or recent_text.count('\n') >= 2:
                        break

        # ë””ì½”ë”©
        generated_text = self.tokenizer.decode(generated_tokens)
        return generated_text

    def answer_question(self, question):
        """
        ì§ˆë¬¸ì— ë‹µë³€ (DB ê²€ìƒ‰ â†’ ì›¹ ê²€ìƒ‰ ìš°ì„ )

        Args:
            question: ì§ˆë¬¸

        Returns:
            answer: ë‹µë³€
        """
        print(f"\nâ“ ì§ˆë¬¸: {question}")
        print("-"*70)

        # 1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê²€ìƒ‰
        cached_data = self.search_qa_database(question)
        if cached_data:
            answer = cached_data['answer']
            avg_rating = cached_data.get('avg_rating')
            if avg_rating:
                print(f"  â­ í‰ê·  í‰ì : {avg_rating:.1f}/5.0")
            return answer

        # 2. ì›¹ ê²€ìƒ‰ (ìš°ì„ )
        print(f"  ğŸ†• ìƒˆë¡œìš´ ì§ˆë¬¸ì…ë‹ˆë‹¤.")
        web_answer = self.search_web(question)

        if web_answer and not web_answer.startswith("'"):  # ìœ íš¨í•œ ë‹µë³€
            # DBì— ì €ì¥
            self.add_qa_pair(question, web_answer)
            print(f"  ğŸ’¾ ë‹µë³€ì„ DBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            return web_answer

        # 3. LLM ëª¨ë¸ ì‚¬ìš© (ë°±ì—…)
        if self.trained:
            print(f"  ğŸ¤– LLM ëª¨ë¸ë¡œ ìƒì„± ì¤‘...")
            llm_response = self.generate_response(question, max_tokens=100, temperature=0.7)
            # ì§ˆë¬¸ ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ
            if llm_response.startswith(question):
                llm_answer = llm_response[len(question):].strip()
            else:
                llm_answer = llm_response

            if llm_answer:
                self.add_qa_pair(question, llm_answer)
                print(f"  ğŸ’¾ LLM ë‹µë³€ì„ DBì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                return llm_answer

        # 4. ê¸°ë³¸ ë‹µë³€
        return web_answer if web_answer else "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def show_statistics(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ í‘œì‹œ"""
        print("\n" + "="*70)
        print("ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
        print("="*70)
        print(f"ì´ QA ìŒ ìˆ˜: {len(self.qa_database)} ê°œ")

        if self.qa_database:
            # ê°€ì¥ ë§ì´ ì ‘ê·¼ëœ ì§ˆë¬¸
            sorted_qa = sorted(
                self.qa_database.items(),
                key=lambda x: x[1].get('access_count', 0),
                reverse=True
            )

            print(f"\nğŸ“ˆ ê°€ì¥ ë§ì´ ì§ˆë¬¸ëœ Top 5:")
            for i, (q, data) in enumerate(sorted_qa[:5], 1):
                count = data.get('access_count', 0)
                avg_rating = data.get('avg_rating')
                rating_str = f", â­ {avg_rating:.1f}" if avg_rating else ""
                print(f"  {i}. {q} (ì ‘ê·¼: {count}íšŒ{rating_str})")

            # ìµœê·¼ ì¶”ê°€ëœ ì§ˆë¬¸
            recent_qa = sorted(
                self.qa_database.items(),
                key=lambda x: x[1].get('timestamp', ''),
                reverse=True
            )

            print(f"\nğŸ†• ìµœê·¼ ì¶”ê°€ëœ ì§ˆë¬¸ 5ê°œ:")
            for i, (q, data) in enumerate(recent_qa[:5], 1):
                timestamp = data.get('timestamp', '')
                if timestamp:
                    dt = datetime.fromisoformat(timestamp)
                    time_str = dt.strftime('%Y-%m-%d %H:%M')
                else:
                    time_str = 'ì•Œ ìˆ˜ ì—†ìŒ'
                print(f"  {i}. {q} ({time_str})")

            # í‰ê·  í‰ì ì´ ë†’ì€ ì§ˆë¬¸
            rated_qa = [(q, d) for q, d in self.qa_database.items() if d.get('avg_rating')]
            if rated_qa:
                sorted_rated = sorted(rated_qa, key=lambda x: x[1]['avg_rating'], reverse=True)
                print(f"\nâ­ í‰ì ì´ ë†’ì€ ë‹µë³€ Top 5:")
                for i, (q, data) in enumerate(sorted_rated[:5], 1):
                    rating = data['avg_rating']
                    count = len(data.get('ratings', []))
                    print(f"  {i}. {q} (í‰ê· : {rating:.1f}/5.0, í‰ê°€: {count}íšŒ)")

        print()

    def export_training_data(self, output_path='training_data.txt'):
        """í•™ìŠµ ë°ì´í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥"""
        if not self.qa_database:
            print("âš ï¸  ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        with open(output_path, 'w', encoding='utf-8') as f:
            for question, data in self.qa_database.items():
                answer = data['answer']
                # ì§ˆë¬¸-ë‹µë³€ í˜•ì‹ìœ¼ë¡œ ì €ì¥
                f.write(f"Q: {question}\n")
                f.write(f"A: {answer}\n")
                f.write("\n")

        print(f"âœ… í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"   - {len(self.qa_database)} ê°œ QA ìŒ")

    def chat(self):
        """ì¸í„°ë™í‹°ë¸Œ ì±„íŒ… ëª¨ë“œ"""
        print("="*70)
        print("ğŸ’¬ í•œêµ­ì–´/ì˜ì–´ QA ì±—ë´‡")
        print("="*70)
        print()
        print("ê¸°ëŠ¥:")
        print("  - í•œêµ­ì–´/ì˜ì–´ ì§ˆë¬¸-ë‹µë³€ ì§€ì›")
        print("  - ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€ ìƒì„±")
        print("  - ë‹µë³€ ìë™ ì €ì¥ ë° í‰ê°€ ì‹œìŠ¤í…œ")
        print("  - ë™ì¼ ì§ˆë¬¸ì— ë¹ ë¥¸ ë‹µë³€ ì œê³µ")
        if self.trained:
            print("  - LLM ëª¨ë¸ ë°±ì—… ì§€ì›")
        print()
        print("ëª…ë ¹ì–´:")
        print("  /stats     - í†µê³„ ë³´ê¸°")
        print("  /export    - í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
        print("  /clear     - ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")
        print("  /help      - ë„ì›€ë§")
        print("  quit/exit  - ì¢…ë£Œ")
        print()
        print("-"*70)

        last_question = None
        last_answer = None

        while True:
            try:
                user_input = input("\nğŸ“ ì§ˆë¬¸: ").strip()

                if not user_input:
                    print("âš ï¸  ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue

                # ì¢…ë£Œ
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("\nğŸ’¾ ë³€ê²½ì‚¬í•­ì„ ì €ì¥í•˜ëŠ” ì¤‘...")
                    self.save_qa_database()
                    print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                # í†µê³„
                if user_input.lower() == '/stats':
                    self.show_statistics()
                    continue

                # ë‚´ë³´ë‚´ê¸°
                if user_input.lower() == '/export':
                    self.export_training_data()
                    continue

                # ì´ˆê¸°í™”
                if user_input.lower() == '/clear':
                    confirm = input("ì •ë§ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
                    if confirm.lower() == 'y':
                        self.qa_database = {}
                        self.save_qa_database()
                        print("âœ… ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    continue

                # ë„ì›€ë§
                if user_input.lower() == '/help':
                    print("\nì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹:")
                    print("  /stats  - ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
                    print("  /export - í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
                    print("  /clear  - ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”")
                    print("  /help   - ë„ì›€ë§")
                    print("\në‹µë³€ í‰ê°€:")
                    print("  ë‹µë³€ í›„ 1~5 ì‚¬ì´ ìˆ«ìë¡œ í‰ê°€ ê°€ëŠ¥")
                    print("  Enter ì…ë ¥ ì‹œ í‰ê°€ ì—†ì´ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ")
                    continue

                # ì§ˆë¬¸ ë‹µë³€
                answer = self.answer_question(user_input)
                print(f"\nğŸ’¬ ë‹µë³€:\n{answer}")
                print("-"*70)

                # ë‹µë³€ í‰ê°€ ìš”ì²­
                last_question = user_input
                last_answer = answer

                try:
                    rating_input = input("\nâ­ ë‹µë³€ í‰ê°€ (1-5, Enter=ê±´ë„ˆë›°ê¸°): ").strip()

                    if rating_input and rating_input.isdigit():
                        rating = int(rating_input)
                        if 1 <= rating <= 5:
                            self.add_qa_pair(last_question, last_answer, rating)
                            print(f"âœ… í‰ê°€ ì™„ë£Œ: {rating}/5.0")
                        else:
                            print("âš ï¸  1~5 ì‚¬ì´ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                    elif rating_input:
                        print("âš ï¸  ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                except:
                    pass  # Enterë§Œ ëˆ„ë¥¸ ê²½ìš°

            except KeyboardInterrupt:
                print("\n\nğŸ’¾ ë³€ê²½ì‚¬í•­ì„ ì €ì¥í•˜ëŠ” ì¤‘...")
                self.save_qa_database()
                print("ğŸ‘‹ ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()


def train_new_model():
    """ìƒˆë¡œìš´ ëª¨ë¸ í•™ìŠµ"""
    print("\nğŸš€ ìƒˆë¡œìš´ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤...")
    print("ì´ ì‘ì—…ì€ ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")

    try:
        import training_pipeline
        training_pipeline.main()
        print("\nâœ… í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("ì´ì œ ì±—ë´‡ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")
        return True
    except Exception as e:
        print(f"\nâŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n" + "="*70)
    print("ğŸ¤– í•œêµ­ì–´/ì˜ì–´ QA ì±—ë´‡")
    print("="*70)
    print()

    # ì²´í¬í¬ì¸íŠ¸ í™•ì¸ (ì„ íƒì‚¬í•­)
    checkpoint_path = 'checkpoints/best_model.pt'

    if not os.path.exists(checkpoint_path):
        print("âš ï¸  í•™ìŠµëœ LLM ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ì›¹ ê²€ìƒ‰ ê¸°ë°˜ìœ¼ë¡œë§Œ ë™ì‘í•©ë‹ˆë‹¤.")
        print()

        # ì‚¬ìš©ìì—ê²Œ ì„ íƒ ì œê³µ
        choice = input("ìƒˆë¡œìš´ ëª¨ë¸ì„ í•™ìŠµí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n/skip): ").strip().lower()

        if choice == 'y':
            success = train_new_model()
            if not success:
                print("\nâš ï¸  í•™ìŠµ ì‹¤íŒ¨. ì›¹ ê²€ìƒ‰ ëª¨ë“œë¡œ ê³„ì†í•©ë‹ˆë‹¤.")
        elif choice == 'skip' or choice == 's':
            print("\nì›¹ ê²€ìƒ‰ ëª¨ë“œë¡œ ê³„ì†í•©ë‹ˆë‹¤.")
        else:
            print("\në‚˜ì¤‘ì— í•™ìŠµí•˜ë ¤ë©´: python training_pipeline.py")
            print("ì›¹ ê²€ìƒ‰ ëª¨ë“œë¡œ ê³„ì†í•©ë‹ˆë‹¤.")
            print()

    # ì±—ë´‡ ì‹¤í–‰ (LLM ëª¨ë¸ ì—†ì–´ë„ ë™ì‘)
    chatbot = LLMChatbot(checkpoint_path)
    chatbot.chat()


if __name__ == "__main__":
    main()
